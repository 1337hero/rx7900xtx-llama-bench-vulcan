==============================================
  Vulkan Benchmark for llama.cpp
  Thread: https://github.com/ggml-org/llama.cpp/discussions/10879
  Date: Thu Dec 11 02:36:39 PM MST 2025
==============================================

=== SYSTEM INFORMATION ===
OS: Linux 6.17.9-zen1-1-zen
Distro: Arch Linux

=== VULKAN INFORMATION ===
	driverVersion      = 25.3.1
	deviceName         = AMD Radeon RX 7900 XTX (RADV NAVI31)
	driverName         = radv
	driverInfo         = Mesa 25.3.1-arch1.2
	driverVersion      = 25.3.1
	deviceName         = AMD Radeon RX 7900 XTX (RADV NAVI31)
	driverName         = radv
	driverInfo         = Mesa 25.3.1-arch1.2

=== BUILD INFO ===
Commit: a81a56957
Model: /home/mikekey/Projects/0_AI/llama.cpp/models/llama-2-7b.Q4_0.gguf

=== VULKAN SETTINGS ===
Coopmat: ENABLED (KHR_coopmat works on RDNA3)
Flash Attention: 1
Batch size: 512
See: https://github.com/ggml-org/llama.cpp/discussions/10879

==============================================
  CANONICAL 7B Q4_0 BENCHMARKS
==============================================

### GPU 0 ONLY (pciBus 6 - bottom slot, display) ###
ggml_vulkan: Found 1 Vulkan devices:
ggml_vulkan: 0 = AMD Radeon RX 7900 XTX (RADV NAVI31) (radv) | uma: 0 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat
| model                          |       size |     params | backend    | ngl | n_batch | fa |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | ------: | -: | --------------: | -------------------: |
| llama 7B Q4_0                  |   3.56 GiB |     6.74 B | Vulkan     | 100 |     512 |  1 |           pp512 |      3229.07 ± 53.81 |
| llama 7B Q4_0                  |   3.56 GiB |     6.74 B | Vulkan     | 100 |     512 |  1 |           tg128 |        150.97 ± 0.05 |

build: a81a56957 (7361)

### GPU 1 ONLY (pciBus 15 - top slot, compute) ###
ggml_vulkan: Found 1 Vulkan devices:
ggml_vulkan: 0 = AMD Radeon RX 7900 XTX (RADV NAVI31) (radv) | uma: 0 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat
| model                          |       size |     params | backend    | ngl | n_batch | fa |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | ------: | -: | --------------: | -------------------: |
| llama 7B Q4_0                  |   3.56 GiB |     6.74 B | Vulkan     | 100 |     512 |  1 |           pp512 |      3290.92 ± 37.67 |
| llama 7B Q4_0                  |   3.56 GiB |     6.74 B | Vulkan     | 100 |     512 |  1 |           tg128 |        172.86 ± 0.23 |

build: a81a56957 (7361)

### DUAL GPU (note: slower for small models due to PCIe overhead) ###
ggml_vulkan: Found 2 Vulkan devices:
ggml_vulkan: 0 = AMD Radeon RX 7900 XTX (RADV NAVI31) (radv) | uma: 0 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat
ggml_vulkan: 1 = AMD Radeon RX 7900 XTX (RADV NAVI31) (radv) | uma: 0 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat
| model                          |       size |     params | backend    | ngl | n_batch | fa |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | ------: | -: | --------------: | -------------------: |
| llama 7B Q4_0                  |   3.56 GiB |     6.74 B | Vulkan     | 100 |     512 |  1 |           pp512 |      2546.13 ± 18.25 |
| llama 7B Q4_0                  |   3.56 GiB |     6.74 B | Vulkan     | 100 |     512 |  1 |           tg128 |        129.80 ± 0.34 |

build: a81a56957 (7361)

==============================================
  BENCHMARK COMPLETE
==============================================
